{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97946ec5",
   "metadata": {},
   "source": [
    "# Experiment\n",
    "In this notebook the simple Frozen Lake environment of Gymnasium will be study.\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34c7ad30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53dc45c",
   "metadata": {},
   "source": [
    "## Setting up the Environments\n",
    "I created one for training to go faster and another for visualising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94dce3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_env = gym.make('FrozenLake-v1', map_name=\"8x8\", is_slippery=True)\n",
    "testing_env = gym.make('FrozenLake-v1', map_name=\"8x8\", is_slippery=True, render_mode=\"human\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8827146b",
   "metadata": {},
   "source": [
    "This are the states and actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b045d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = training_env.observation_space\n",
    "actions = training_env.action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39600b0",
   "metadata": {},
   "source": [
    "## Collection the Data Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a3ce373",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS = 500000\n",
    "current_state, _ = training_env.reset()\n",
    "num_actions = actions.n\n",
    "num_states = states.n\n",
    "gamma = 0.99\n",
    "\n",
    "data_points = np.zeros((STEPS, 4))\n",
    "\n",
    "\n",
    "for i in range(STEPS):\n",
    "    action = np.random.choice(range(num_actions))\n",
    "    next_state, reward, terminated, truncated, info = training_env.step(action)\n",
    "    data_points[i] = [current_state, action, reward, next_state]\n",
    "    current_state = next_state\n",
    "    if terminated or truncated:\n",
    "        current_state, info = training_env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9f1b53",
   "metadata": {},
   "source": [
    "## Building the Reward Matrix and Transition Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cd9ce02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_189485/4150191650.py:20: RuntimeWarning: invalid value encountered in divide\n",
      "  transition_tensor = state_action_tensor / np.sum(state_action_tensor, axis=2, keepdims=True)\n"
     ]
    }
   ],
   "source": [
    "transition_tensor = np.zeros((states.n, actions.n, states.n), dtype=np.float32)\n",
    "\n",
    "state_action_counter = np.zeros((states.n, actions.n), dtype=np.int32)\n",
    "# for each action states x states\n",
    "state_action_tensor = np.zeros((states.n, actions.n,states.n), dtype=np.float32)\n",
    "\n",
    "reward_matrix = np.zeros((states.n, actions.n), dtype=np.float32)\n",
    "\n",
    "for i in range(STEPS):\n",
    "    current_state, action, reward, next_state = data_points[i]\n",
    "    current_state = int(current_state)\n",
    "    action = int(action)\n",
    "    next_state = int(next_state)\n",
    "    state_action_counter[current_state, action] += 1\n",
    "    state_action_tensor[current_state, action, next_state] += 1\n",
    "    reward_matrix[current_state, action] += reward\n",
    "\n",
    "# Normalize transition_tensor over next states (axis=2), not over actions!\n",
    "# transition_tensor[state, action, next_state] = P(next_state | state, action)\n",
    "transition_tensor = state_action_tensor / np.sum(state_action_tensor, axis=2, keepdims=True)\n",
    "# Normalize reward_matrix by the count of (state, action) visits\n",
    "reward_matrix = reward_matrix / np.maximum(state_action_counter, 1)  # Avoid division by zero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d71b47",
   "metadata": {},
   "source": [
    "Just filtering some NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52a83720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.66608393, 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.3304396 , 0.33450422, 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.33200338, 0.3398833 , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.6666332 , 0.3333668 , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ]],\n",
       "\n",
       "       [[0.34360543, 0.33278254, 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.32882285, 0.        , 0.33546406, ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.34055266, 0.33615467, ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.33227047, 0.3364402 , 0.33128935, ..., 0.        ,\n",
       "         0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.3314394 , 0.34212664, ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.3295228 , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.33555585, ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.3325556 , 0.33516333, ..., 0.        ,\n",
       "         0.        , 0.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.25      ,\n",
       "         0.75      , 0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.33333334,\n",
       "         0.33333334, 0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.6666667 , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        , ..., 0.25      ,\n",
       "         0.25      , 0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 1.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "         0.        , 0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turn all the nans into 0\n",
    "reward_matrix = np.nan_to_num(reward_matrix, -1)\n",
    "\n",
    "transition_tensor = np.nan_to_num(transition_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91adcba6",
   "metadata": {},
   "source": [
    "## The core Value Iteration algorithm\n",
    "Here a simple [[Iteration Algorithms#Value Iteration|Value Iteration]] was implemented, which can be further optimised to build the transition tensor, and reward through Value Iteration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cdfb881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 2, 2, 1, 3, 3, 0, 0, 2, 3,\n",
       "       2, 2, 3, 3, 3, 1, 0, 0, 2, 2, 0, 3, 3, 0, 2, 1, 3, 2, 0, 0, 0, 1,\n",
       "       3, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 2, 0, 1, 0, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err = 1\n",
    "i = 0\n",
    "\n",
    "V = np.ones(states.n)\n",
    "\n",
    "while err > 1e-8:\n",
    "  Q = np.zeros((states.n, num_actions))\n",
    "\n",
    "  for action in range(num_actions):\n",
    "    Q[:,action] = reward_matrix[:,action] + gamma * transition_tensor[:,action] @ V\n",
    "\n",
    "  Vnew = np.max(Q, axis=1)\n",
    "  err = np.linalg.norm(V - Vnew)\n",
    "  V = Vnew\n",
    "  i+=1\n",
    "\n",
    "np.argmax(Q, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e86a056",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fab23bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "display Surface quit",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m obs, info \u001b[38;5;241m=\u001b[39m \u001b[43mtesting_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m      6\u001b[0m     action \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(Q[obs])\n",
      "File \u001b[0;32m/mnt/hdd1/Repos/ds_be_like/.venv/lib/python3.10/site-packages/gymnasium/wrappers/common.py:146\u001b[0m, in \u001b[0;36mTimeLimit.reset\u001b[0;34m(self, seed, options)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resets the environment with :param:`**kwargs` and sets the number of steps elapsed to zero.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \n\u001b[1;32m    138\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;124;03m    The reset environment\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 146\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/hdd1/Repos/ds_be_like/.venv/lib/python3.10/site-packages/gymnasium/core.py:333\u001b[0m, in \u001b[0;36mWrapper.reset\u001b[0;34m(self, seed, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mreset\u001b[39m(\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, seed: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, options: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    331\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    332\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Uses the :meth:`reset` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 333\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/hdd1/Repos/ds_be_like/.venv/lib/python3.10/site-packages/gymnasium/wrappers/common.py:400\u001b[0m, in \u001b[0;36mOrderEnforcing.reset\u001b[0;34m(self, seed, options)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resets the environment with `kwargs`.\"\"\"\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 400\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/hdd1/Repos/ds_be_like/.venv/lib/python3.10/site-packages/gymnasium/core.py:333\u001b[0m, in \u001b[0;36mWrapper.reset\u001b[0;34m(self, seed, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mreset\u001b[39m(\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, seed: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, options: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    331\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[1;32m    332\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Uses the :meth:`reset` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 333\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/hdd1/Repos/ds_be_like/.venv/lib/python3.10/site-packages/gymnasium/wrappers/common.py:295\u001b[0m, in \u001b[0;36mPassiveEnvChecker.reset\u001b[0;34m(self, seed, options)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_reset_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, seed\u001b[38;5;241m=\u001b[39mseed, options\u001b[38;5;241m=\u001b[39moptions)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 295\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/hdd1/Repos/ds_be_like/.venv/lib/python3.10/site-packages/gymnasium/envs/toy_text/frozen_lake.py:347\u001b[0m, in \u001b[0;36mFrozenLakeEnv.reset\u001b[0;34m(self, seed, options)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlastaction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 347\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ms), {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprob\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m}\n",
      "File \u001b[0;32m/mnt/hdd1/Repos/ds_be_like/.venv/lib/python3.10/site-packages/gymnasium/envs/toy_text/frozen_lake.py:363\u001b[0m, in \u001b[0;36mFrozenLakeEnv.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_render_text()\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# self.render_mode in {\"human\", \"rgb_array\"}:\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_render_gui\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender_mode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/hdd1/Repos/ds_be_like/.venv/lib/python3.10/site-packages/gymnasium/envs/toy_text/frozen_lake.py:433\u001b[0m, in \u001b[0;36mFrozenLakeEnv._render_gui\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    430\u001b[0m pos \u001b[38;5;241m=\u001b[39m (x \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcell_size[\u001b[38;5;241m0\u001b[39m], y \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcell_size[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    431\u001b[0m rect \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m*\u001b[39mpos, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcell_size)\n\u001b[0;32m--> 433\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwindow_surface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mice_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m desc[y][x] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_surface\u001b[38;5;241m.\u001b[39mblit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhole_img, pos)\n",
      "\u001b[0;31merror\u001b[0m: display Surface quit"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "obs, info = testing_env.reset()\n",
    "\n",
    "while True:\n",
    "    action = np.argmax(Q[obs])\n",
    "    obs, reward, terminated, truncated, info = testing_env.step(action)\n",
    "    # sleep for 0.1 seconds\n",
    "    time.sleep(0.1)\n",
    "    if terminated or truncated:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571f8288",
   "metadata": {},
   "source": [
    "Note that sometimes it will fall into the whole since it has a probability of falling on it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dceb3879",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_env.close()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
